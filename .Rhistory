woGSR_path_lmeT <- sapply(1:ncol(ConnMx_path_woGSR), function(x){
info$fc <- ConnMx_path_woGSR[,x]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
# Compute head motion relationships (edgewise)
tic <- Sys.time()
woGSR_edge_lmeT <- sapply(1:nrow(tri_pos), function(x){
info$fc <- ConnMx[tri_pos[x,1],tri_pos[x,2],]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
toc <- Sys.time()
# Compare to euclidean distance
#plot(tri_dist,woGSR_edge_lmeT); abline(lm(woGSR_edge_lmeT~tri_dist), col="red", lwd=3)
#-------------------------------------------------------------------------
# Same for Global Signal Regression data
# Create time-series file list
ts_files <- paste0("https://raw.githubusercontent.com/BrainMapINB/Pubertal_Connectome/main/Brain/GSR/sub-",
info$BIDS.ID,"/ses-",info$Session,"/pp150v_wGSR_NIHPD_MNI_P264_ts.txt")
# Compute connectivity matrices
ConnMx <- sapply(ts_files,
function(x){
ts <- read.table(x)
cmx <- cor(ts)
if(sum(is.na(cmx))>0) cmx[is.na(cmx)] <- 0
cmx
}
)
# Reshape object
ConnMx <- array(ConnMx, dim = ConnMx_dim)
# Substract diagonal
for(ii in 1:ConnMx_dim[3]) diag(ConnMx[,,ii]) <- 0
# Apply cost threshold
# Apply thresholds to Connectivity Matrix
ConnMx_th <- apply(ConnMx,3,function(x) cost_th_ConnMx(x,0.25))
ConnMx_th <- array(ConnMx_th,dim=ConnMx_dim)
# Fisher's z transformation
ConnMx <- fisherz(ConnMx)
ConnMx_th <- fisherz(ConnMx_th)
# Compute graph theory measures
ConnMx_str_wGSR <- apply(ConnMx,3:2,sum)
ConnMx_deg_wGSR <- apply(ConnMx_th,3:2,sum)
ConnMx_clus_wGSR <- t(sapply(1:ConnMx_dim[3], function(x) iCC_w(ConnMx_th[,,x])))
ConnMx_eff_wGSR <- t(sapply(1:ConnMx_dim[3], function(x) iEff_w(ConnMx_th[,,x])))
ConnMx_path_wGSR <- t(sapply(1:ConnMx_dim[3], function(x) iL_w(ConnMx_th[,,x])))
# Compute head motion relationships (strength and degree)
wGSR_str_lmeT <- sapply(1:ncol(ConnMx_str_wGSR), function(x){
info$fc <- ConnMx_str_wGSR[,x]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
wGSR_deg_lmeT <- sapply(1:ncol(ConnMx_deg_wGSR), function(x){
info$fc <- ConnMx_deg_wGSR[,x]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
wGSR_clus_lmeT <- sapply(1:ncol(ConnMx_clus_wGSR), function(x){
info$fc <- ConnMx_clus_wGSR[,x]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
wGSR_eff_lmeT <- sapply(1:ncol(ConnMx_eff_wGSR), function(x){
info$fc <- ConnMx_eff_wGSR[,x]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
wGSR_path_lmeT <- sapply(1:ncol(ConnMx_path_wGSR), function(x){
info$fc <- ConnMx_path_wGSR[,x]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
# Compute head motion relationships (edgewise)
tic <- Sys.time()
wGSR_edge_lmeT <- sapply(1:nrow(tri_pos), function(x){
info$fc <- ConnMx[tri_pos[x,1],tri_pos[x,2],]
summary(lmer(fc~FDRMS + (1|BIDS.ID), data = info))$coefficients[2,3]
})
toc <- Sys.time()
# Compare to euclidean distance
#plot(tri_dist,wGSR_edge_lmeT); abline(lm(wGSR_edge_lmeT~tri_dist), col="red", lwd=3)
#-------------------------------------------------------------------------
# Set datasets
# Edgewise-motion vs distance
edge_motion_dist_data <- data.frame(edge_woGSR=woGSR_edge_lmeT,
edge_wGSR=wGSR_edge_lmeT,
dist=tri_dist)
outname <- "edge_motion_euclidean_dist.csv"
write.csv(x = edge_motion_dist_data, file = outname,
quote = FALSE, row.names = FALSE)
# Edgewise-motion density
tri_n <- length(tri_dist)
edge_motion_data <- data.frame(edge_hm=c(woGSR_edge_lmeT,wGSR_edge_lmeT),
GSR=c(rep("NO",tri_n),rep("YES",tri_n)))
outname <- "edge_motion.csv"
write.csv(x = edge_motion_data, file = outname,
quote = FALSE, row.names = FALSE)
# Graph theory measures
gt_data <- data.frame(str_hm=c(woGSR_str_lmeT,wGSR_str_lmeT),
deg_hm=c(woGSR_deg_lmeT,wGSR_deg_lmeT),
clus_hm=c(woGSR_clus_lmeT,wGSR_clus_lmeT),
eff_hm=c(woGSR_eff_lmeT,wGSR_eff_lmeT),
path_hm=c(woGSR_path_lmeT,wGSR_path_lmeT),
GSR=c(rep("NO",nrow(atlas)),rep("YES",nrow(atlas))))
outname <- "graph_motion.csv"
write.csv(x = gt_data, file = outname,
quote = FALSE, row.names = FALSE)
}
# Load 'ggplot2', 'gridExtra', & 'viridis' package
if(!require(ggplot2)) install.packages("ggplot2"); library(ggplot2)
if(!require(gridExtra)) install.packages("gridExtra"); library(gridExtra)
if(!require(viridis)) install.packages("viridis"); library(viridis)
# Hexbin chart (NO GSR)
edge_dist <- read.csv(qc_files[2])
edge_hm_b1 <- coef(lm(edge_woGSR~dist, data = edge_dist))[2]
g1 <- ggplot(edge_dist, aes(x=dist, y=edge_woGSR) ) +
geom_hex(bins = 70) +
scale_fill_continuous(type = "viridis") +
geom_smooth(method='lm', formula= y~x, color = "red") +
ggtitle(paste0("No GSR (slope=",round(edge_hm_b1, 4),")")) +
xlab("Euclidean Dist. (mm)") +
ylab("Edge-motion (LME-t)") +
theme_bw() + ylim(-5, 5) + xlim(0,170)
g1
# Hexbin chart
edge_hm_b1 <- coef(lm(edge_wGSR~dist, data = edge_dist))[2]
g2 <- ggplot(edge_dist, aes(x=dist, y=edge_wGSR) ) +
geom_hex(bins = 70) +
scale_fill_continuous(type = "viridis") +
geom_smooth(method='lm', formula= y~x, color = "red") +
ggtitle(paste0("with GSR (slope=",round(edge_hm_b1, 4),")")) +
xlab("Euclidean Dist. (mm)") +
ylab("Edge-motion (LME-t)") +
theme_bw() + ylim(-5, 5) + xlim(0,170)
# Arrange plots
g3 <- grid.arrange(g1, g2, nrow = 1, ncol=2)
q()
library(caret)
install.packages("NBR")
library(NBR)
R.version
install.packages("fslr")
library(fslr)
library(mgcv)
head(cars)
fit <- gam(speed ~ s(dist), data = cars)
fit0 <- lm(speed~1, data = cars)
anova(fit0,fit)
install.packages("brainGraph")
library(fslr)
nii <- readnii("~/Downloads/HCP-MMP1/HCP-MMP1/HCP-MMP1/HCP-MMP1_2mm.nii.gz")
table(nii)
names(table(nii))
length(names(table(nii)))
nii <- readnii("~/Downloads/HCP-MMP1/HCP-MMP1/HCP-MMP1/HCP-MMP_1mm.nii.gz")
length(names(table(nii)))
library(NBR)
data(voles)
nbr_result <- nbr_lme_aov(net = voles[,-(1:3)],
nnodes = 16, idata = voles[,1:3],
mod = "~ Session*Sex",
rdm = "~ 1+Session|id",
nperm = 5, na.action = na.exclude, nudist = T
)
nbr_result$nudist
nbr_result$components
nbr_result$fwe$Session
nbr_result$fwe$Session[,2]
nbr_result$fwe$Sex
nbr_result$fwe$Sex[,2]
nbr_result$nudist
sum(nbr_result$fwe$Sex[,2]>nbr_result$nudist[,4])
sum(nbr_result$fwe$Sex[1,2]>nbr_result$nudist[,4])
sum(nbr_result$fwe$Sex[1,2]<nbr_result$nudist[,4])
sum(nbr_result$fwe$Sex[1,2]<nbr_result$nudist[,4])/nrow(nbr_result$nudist)
nbr_result$fwe$Sex
aux <- vector("numeric", length = 0)
rbind(aux,nbr_result$nudist)
aux <- rbind(aux,nbr_result$nudist)
aux
R.version
q()
names(voles)[1:5]
data(voles)
library(NBR)
data(voles)
names(voles)[1:4]
library(nlme)
anova(lme(fixed = ACC.AON ~ Session*Sex,
data = voles,
random = ~ 1+Session|id,
na.action = na.exclude))
qf(0.05, 2, 56, lower.tail = F)
lme(fixed = ACC.AON ~ Session*Sex,
data = voles,
random = ~ 1+Session|id,
na.action = na.exclude)
summary(lme(fixed = ACC.AON ~ Session*Sex,
data = voles,
random = ~ 1+Session|id,
na.action = na.exclude))
qt(0.05, 56, lower.tail = F)
NBR:::voles_nbr
NBR:::voles_nbr$fwe$Session
NBR:::voles_nbr$components$Session
head(NBR:::voles_nbr$nudist)
# Clear workspace
rm(list = ls())
# Read statistical networks
# Load 'R.matlab' package
if(!require("R.matlab")) install.packages("R.matlab"); library(R.matlab)
# Read input stats
# NBS-2tp
aux <- readMat("https://github.com/BrainMapINB/NBR-SLIM/blob/main/Analyses/NBS-2tp/NBS2tp_lobe_stai_F4.mat?raw=true")
NBS2tp_stat <- aux[[1]][[3]][[4]]
NBS2tp_stat[NBS2tp_stat<4] <- 0
NBS2tp_perm <- aux[[1]][[2]][[5]]
# NBS-3tp
aux <- readMat("https://github.com/BrainMapINB/NBR-SLIM/blob/main/Analyses/NBS-3tp/NBS3tp_lobe_stai_F4.mat?raw=true")
NBS3tp_stat <- aux[[1]][[3]][[4]]
NBS3tp_stat[NBS3tp_stat<4] <- 0
NBS3tp_perm <- aux[[1]][[2]][[5]]
# NBR
aux <- read.table("https://raw.githubusercontent.com/BrainMapINB/NBR-SLIM/main/Analyses/NBR-LME/NBR-LME_State_Anxiety_comp.txt", header = T)
NBR_stat <- matrix(0, 8, 8)
for(ii in 1:nrow(aux)) NBR_stat[aux[ii,2],aux[ii,3]] <- aux[ii,5]+4
NBR_stat <- NBR_stat + t(NBR_stat)
aux <- read.table("https://raw.githubusercontent.com/BrainMapINB/NBR-SLIM/main/Analyses/NBR-LME/NBR-LME_State_Anxiety_fwe.txt", header = T)
NBR_perm <- aux[1,4]
aux <- read.table("https://raw.githubusercontent.com/BrainMapINB/NBR-SLIM/main/Analyses/NBR-LME/NBR-LME_State_Anxiety_nudist.txt", header = T)
NBR_perm <- c(NBR_perm, aux[,2])
# Find components in NBS permuted matrices
source("https://raw.githubusercontent.com/BrainMapINB/NBR-SLIM/main/Scripts/Auxiliary/find_components.R")
# Homogenizate data
all_perm <- matrix(0, nrow = 1001, ncol = 3)
tri_pos <- which(upper.tri(matrix(nrow = 8, ncol = 8)), arr.ind = T)
# NBR-2tp
all_perm[,1] <- sapply(1:1001, function(x){ y <- find_components(NBS2tp_perm[x,], 4, tri_pos, 8)
if(is.null(y)) return(0) else return(max(aggregate(y[,5] ~ y[,4], y, sum)[, 2]))})
# NBR-3tp
all_perm[,2] <- sapply(1:1001, function(x){ y <- find_components(NBS3tp_perm[x,], 4, tri_pos, 8)
if(is.null(y)) return(0) else return(max(aggregate(y[,5] ~ y[,4], y, sum)[, 2]))})
# NBR
all_perm[,3] <- NBR_perm
colnames(all_perm) <- c("NBS2tp","NBS3tp","NBR")
all_perm <- as.data.frame(all_perm)
# Load 'corrplot', 'circlize' & 'scales' package
if(!require("corrplot")) install.packages("corrplot"); library(corrplot)
if(!require("circlize")) install.packages("circlize"); library(circlize)
if(!require("scales")) install.packages("scales"); library(scales)
# Corrplots input parameters
mod_labs <- c("NBS2tp","NBS3tp","NBR")
lob_labs <- c("FRT","PAR","TEMP","OCC","INS","CING","SUB","CBL")
colorcito <- colorRampPalette(c("white","yellow","orange","red"))
# Chord diagram input parameters
lob_fac <- as.factor(1:length(lob_labs))
levels(lob_fac) <- lob_labs
# Generate panel
par(mfrow=c(3,3))
for(nn in 1:3){
# Corrplot
mat_stat <- get(paste0(mod_labs[nn],"_stat"))
colnames(mat_stat) <- row.names(mat_stat) <- lob_labs
corrplot(mat_stat, is.corr = F,type = "lower", tl.col = "black",
method = "square", cl.cex = 1, cl.lim = c(0,12.5),
diag = F, mar=c(3,1,1,1)+0.1, col = colorcito(100))
# Chord diagram of significant (uncorrected) intra and inter-module effects
# Initialize the plot
circos.clear()
circos.initialize(factors = lob_fac, xlim=c(-1,1))
# Build the regions of track #1
circos.trackPlotRegion(factors = lob_fac, ylim = c(-1,1),
bg.col = "aliceblue",
bg.border = "black")
# Add labels
lob_pos <- ux(29.75, "mm")*(1:nlevels(lob_fac))
circos.text(lob_pos,rep(0,nlevels(lob_fac)),
labels = lob_labs,
facing = "bending.inside", cex=1.4)
# Add a links between a point and another
# Find significant (NBS corrected) weigths
up_tri <- which(upper.tri(mat_stat), arr.ind = T)
sig_tri <- which(mat_stat[upper.tri(mat_stat)]>4)
# Draw links
for(ii in 1:length(sig_tri)){
# Set central position
rnum <- runif(1); p1 <- c(rnum,rnum-1)
rnum <- runif(1); p2 <- c(rnum,rnum-1)
# Set color
fval <- mat_stat[up_tri[sig_tri[ii],1],up_tri[sig_tri[ii],2]]
fper <- round(100*fval/12.5)
fcol <- colorcito(100)[fper]
# Draw link
circos.link(lob_fac[up_tri[sig_tri[ii],1]], p1,
lob_fac[up_tri[sig_tri[ii],2]], p2,
col = scales::alpha(fcol,.9),
border = scales::alpha(fcol,.4),
h.ratio=0.6)
}
# Clear cicle parameters
circos.clear()
# Plot null distributions
d <- density(all_perm[-1,nn])
plot(d, xlim = c(-0.5,20), ylim = c(0,1.8),
xlab = "Strength", axes = F, main = mod_labs[nn], col = "blue")
polygon(d, col = "cyan", border = "blue")
axis(1); axis(2, las=1)
abline(v = all_perm[1,nn], col = "brown", lty=2, lwd = 2)
print(sum(all_perm[-1,nn]>=all_perm[1,nn])/1000)
}
# Chord diagram of significant (uncorrected) intra and inter-module effects
# Initialize the plot
circos.clear()
circos.initialize(factors = lob_fac, xlim=c(-1,1))
# Chord diagram of significant (uncorrected) intra and inter-module effects
# Initialize the plot
circos.clear()
circos.initialize(factors = lob_fac, xlim=c(-1,1))
# Build the regions of track #1
circos.trackPlotRegion(factors = lob_fac, ylim = c(-1,1),
bg.col = "aliceblue",
bg.border = "black")
# Add labels
lob_pos <- ux(29.75, "mm")*(1:nlevels(lob_fac))
circos.text(lob_pos,rep(0,nlevels(lob_fac)),
labels = lob_labs,
facing = "bending.inside", cex=1.4)
# Add a links between a point and another
# Find significant (NBS corrected) weigths
up_tri <- which(upper.tri(mat_stat), arr.ind = T)
sig_tri <- which(mat_stat[upper.tri(mat_stat)]>4)
# Draw links
for(ii in 1:length(sig_tri)){
# Set central position
rnum <- runif(1); p1 <- c(rnum,rnum-1)
rnum <- runif(1); p2 <- c(rnum,rnum-1)
# Set color
fval <- mat_stat[up_tri[sig_tri[ii],1],up_tri[sig_tri[ii],2]]
fper <- round(100*fval/12.5)
fcol <- colorcito(100)[fper]
# Draw link
circos.link(lob_fac[up_tri[sig_tri[ii],1]], p1,
lob_fac[up_tri[sig_tri[ii],2]], p2,
col = scales::alpha(fcol,.9),
border = scales::alpha(fcol,.4),
h.ratio=0.6)
}
# Clear cicle parameters
circos.clear()
library(NBR)
data(voles)
nbr_result <- nbr_lme(net = voles[,-(1:3)], nnodes = 16,
idata = voles[,1:3], mod = "~ Session*Sex",
rdm = "~ 1+Session|id", nperm = 5,
na.action = na.exclude, cores = 4
)
show(nbr_result)
aux <- matrix(0, 90, 90)
aux2 <- upper.tri(aux)
aux2 <- which(upper.tri(aux), arr.ind = T)
aux2 <- which(upper.tri(aux)==T, arr.ind = T)
y <- sample(c(0,1), 100, replace = T)
x <- rnorm(100)
# Fit logit
fit <- summary(glm(y~x, family = binomial("logit")))
print(fit)
# Fit logit
fit <- summary(glm(y~scale(x), family = binomial("logit")))
print(fit)
# Z-scores
fit$coefficients
# Z-scores
fit$coefficients[,3]
# Odds ratio
exp(fit$coefficients[,1])
# Random data
y <- sample(c(0,1), 100, replace = T)
x1 <- sample(c(0,1), 100, replace = T)
x2 <- sample(c(0,1), 100, replace = T)
# Fit logit
fit <- summary(glm(y~x1+x2, family = binomial("logit")))
print(fit)
# Z-scores
fit$coefficients[,3] #z-value
fit$coefficients[,4] #p-value
# Odds ratio
exp(fit$coefficients[,1])
# Random data
y <- factor(sample(c(0,1), 100, replace = T))
x1 <- factor(sample(c(0,1), 100, replace = T))
x2 <- factor(sample(c(0,1), 100, replace = T))
# Fit logit
fit <- summary(glm(y~x1+x2, family = binomial("logit")))
print(fit)
# Z-scores
fit$coefficients[,3] #z-value
fit$coefficients[,4] #p-value
# Odds ratio
exp(fit$coefficients[,1])
# Random data
depression <- factor(sample(c(0,1), 100, replace = T))
mother <- factor(sample(c(0,1), 100, replace = T))
father <- factor(sample(c(0,1), 100, replace = T))
sex <- factor(sample(c("M","F"), 100, replace = T))
# Fit logit models
fit_mother <- summary(glm(depression~mother+sex, family = binomial("logit")))
fit_father <- summary(glm(depression~father+sex, family = binomial("logit")))
# Fit logit models
fit_mother <- glm(depression~mother+sex, family = binomial("logit"))
fit_father <- glm(depression~father+sex, family = binomial("logit"))
# Likelihood ratio test
anova(fit_mother,fit_father)
# Random data
depression <- factor(sample(c(0,1), 100, replace = T))
mother <- factor(sample(c(0,1), 100, replace = T))
# Fit logit models
fit_mother <- glm(depression~mother+sex, family = binomial("logit"))
fit_father <- glm(depression~father+sex, family = binomial("logit"))
# Likelihood ratio test
anova(fit_mother,fit_father)
mother <- factor(sample(c(0,1), 100, replace = T))
# Likelihood ratio test
anova(fit_mother,fit_father)
# Random data
depression <- factor(sample(c(0,1), 100, replace = T))
mother <- factor(c(depression[1:50],sample(c(0,1), 50, replace = T)))
father <- factor(sample(c(0,1), 100, replace = T))
sex <- factor(sample(c("M","F"), 100, replace = T))
# Fit logit models
fit_mother <- glm(depression~mother+sex, family = binomial("logit"))
fit_father <- glm(depression~father+sex, family = binomial("logit"))
# Likelihood ratio test
anova(fit_mother,fit_father)
fit_all <- glm(depression~mother+father+sex, family = binomial("logit"))
# Likelihood ratio test
drop1(fit_all)
anova(fit_mother,fit_all)
anova(fit_father,fit_all)
# Likelihood ratio test
library(epicalc)
# Likelihood ratio test
if(!require(epicalc)) install.packages("epicalc"); library(epicalc)
# Likelihood ratio test
if(!require(lmtest)) install.packages("lmtest"); library(lmtest)
lrtest(fit_mother,fit_father)
logLik(fit_mother)
logLik(fit_father)
summary(fit_mother)
depression[1:50]
mother
mother <- factor(c(as.integer(depression[1:50]),sample(c(0,1), 50, replace = T)))
mother
as.integer(depression[1:50])
# Random data
depression <- factor(sample(c(1,2), 100, replace = T))
mother <- factor(c(depression[1:50],sample(c(1,2), 50, replace = T)))
father <- factor(sample(c(1,2), 100, replace = T))
sex <- factor(sample(c("M","F"), 100, replace = T))
# Fit logit models
fit_mother <- glm(depression~mother+sex, family = binomial("logit"))
fit_father <- glm(depression~father+sex, family = binomial("logit"))
fit_all <- glm(depression~mother+father+sex, family = binomial("logit"))
# Likelihood ratio test
if(!require(lmtest)) install.packages("lmtest"); library(lmtest)
lrtest(fit_mother,fit_father)
library(NBR)
NBR:::voles_nbr[[1]]
install.packages("lme4")
library(lme4)
library(lme4)
pi
1.47(1.47+(pi^2)/3)
1.47/(1.47+(pi^2)/3)
library(sjstats)
install.packages("sjstats")
1.47^2(1.47^2+(pi^2)/3)
1.47^2/(1.47^2+(pi^2)/3)
102/(102+pi^2/3)
?sjstats::icc
library(rethinking)
install.packages("rethinking")
(pi^2 / 3)
(3.289868*0.3009313)/(1+0.3009313)
sqrt(0.7610119)
1.19^2
tau2 <- 1.19^2
tau2 / (tau2 + (pi^2 / 3) )
(3.289868*0.3009313)/(1-0.3009313)
library(lme4)
library(lme4)
help("convergence")
library(lme4)
32/sqrt(2/1000)
32*sqrt(2/1000)
help("convergence")
??convergence
?lme4::convergence
sqrt(0.086)
q()
q()
# Load NBR
if(!require(NBR)) install.packages("NBR"); library(NBR)
setwd("Documents/UNIVERSIDAD/MCGILL/NeuroHackademy/Project/NBPy/")
# Load data from example 1
data1 <- read.csv("data/sample_input_1.csv")
nbr_result <- nbr_lm(net = data1[,-(1:3)], nnodes = 28,
idata = data1[,1:3], mod = "~ Group + Sex * Age",
thrP = 0.01, nperm = 1)
print(nbr_result$fwe)
# Load number of availaible cores
library(parallel)
ncores <- detectCores()
# Load NBR
if(!require(NBR)) install.packages("NBR"); library(NBR)
# Load number of available cores
library(parallel)
ncores <- detectCores()
# Load data from example 1
data1 <- read.csv("data/sample_input_2.csv")
